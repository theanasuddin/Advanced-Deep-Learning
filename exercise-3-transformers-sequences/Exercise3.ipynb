{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a52ca81",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f87f0620c027b7cbdb9cc60064f8ba3f",
     "grade": false,
     "grade_id": "cell-aa447871a4b4efb4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# MNIST Classification with Vision Transformer \n",
    "In this exercise we will explore the transformers by implementing multihead attention. This hands-on experiment follows naturally from your previous theoretical exercise\n",
    "We will use the **Mint dataset** — a small image dataset.\n",
    "\n",
    "### **Stages**\n",
    "\n",
    "1. **Import Necessary Libraries** – Load required Python and deep learning packages.  \n",
    "2. **Download and Load the MNIST Dataset** – Explore its structure and format.  \n",
    "3. **Preprocess and Prepare DataLoaders** – Normalize, resize, and split the dataset into training, validation, and test sets. \n",
    "5. **Define and Train Models** – Implement the standard single layer transformer encoder network. \n",
    "\n",
    "Complete the code blocks marked with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874a48f-f5cd-4cb0-8a59-c2a99777c872",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43dcfc02f02a2bfde639b50b67881132",
     "grade": true,
     "grade_id": "cell-77d26ddf8f660f3f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not delete this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4741c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a557fd0b5779e8e3e2e7a7d557b0df7",
     "grade": false,
     "grade_id": "cell-243aab422dd06e1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Deliverables:** <br>\n",
    "\n",
    "Submit the completed notebook (Exercise1.ipynb) and your trained model (best_model.pth) to moodle. \n",
    "Do not change the name of the notebook file. It may result in 0 points for the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90716d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f132e19beca3601b43c32631aafece7d",
     "grade": false,
     "grade_id": "cell-2b8636829c7c7439",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1. Import Necessary Libraries\n",
    "\n",
    "In this section, we import the essential Python libraries required for building, training, and evaluating our convolutional residual networks.\n",
    "\n",
    "We will use:\n",
    "- **PyTorch** for model definition, training, and evaluation.  \n",
    "- **Torchvision** for loading and transforming the MNIST dataset.  \n",
    "- **NumPy** for numerical operations.  \n",
    "- **Random** for setting the random seed. \n",
    "- **Sklearn** for calculating f1 score.\n",
    "- **tqdm** for tracking training progress.\n",
    "\n",
    "Make sure all required packages are installed before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf394c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be0a4522bdc782b83002213b1eb5c342",
     "grade": false,
     "grade_id": "cell-8dd0331c53784304",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "# Set seeds\n",
    "torch.cuda.manual_seed_all(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d23531e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f91ccf563c6340b4ec8637e0eba5abe",
     "grade": false,
     "grade_id": "cell-ae05c0b6e70f6b43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 2. Download and Load the MNIST Dataset\n",
    "\n",
    "In this section, we will download the **MNIST** dataset, which contains **60,000 training** and **10,000 test** grayscale images of handwritten digits (0–9), each of size **28×28 pixels**.\n",
    "\n",
    "We will:\n",
    "- Use `torchvision.datasets.MNIST` to download and load the data.  \n",
    "- Apply image transformations such as **tensor conversion** and **normalization** to ensure consistent model training.  \n",
    "- Create **DataLoaders** for both training and testing sets, enabling efficient mini-batch processing.\n",
    "\n",
    "### Normalization Details\n",
    "The images are normalized using the mean and standard deviation of the MNIST dataset:\n",
    "- Mean = 0.1307  \n",
    "- Std  = 0.3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858ec4c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d396bc0cadce6c62ceb9399f4bd8cb2b",
     "grade": false,
     "grade_id": "cell-41b18caee32353b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Download and load training and test sets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define DataLoaders for batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c7df5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9de16272120335884fd5d7c08206c3b7",
     "grade": false,
     "grade_id": "cell-c48fdfe09956c0b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3. Preprocess and Prepare DataLoaders\n",
    "\n",
    "Before training, let’s verify that our MNIST data is correctly loaded and preprocessed.\n",
    "\n",
    "In this stage, we will:\n",
    "- Check the **shape** and **value range** of sample tensors.  \n",
    "- Optionally create a **validation set** (useful for model tuning).  \n",
    "- Confirm the number of samples and batches in our DataLoaders.\n",
    "\n",
    "This ensures that the data pipeline is ready before defining the neural network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4e865",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f288ea8569b612b0a7953d628a85d1f",
     "grade": false,
     "grade_id": "cell-e13b7fa5fade4aa4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect one sample\n",
    "example_data, example_label = train_dataset[0]\n",
    "print(f\"Sample image shape: {example_data.shape}\")\n",
    "print(f\"Label: {example_label}\")\n",
    "print(f\"Tensor value range: {example_data.min():.4f} to {example_data.max():.4f}\")\n",
    "\n",
    "# Optional: create a validation split (e.g., 10% of training set)\n",
    "val_size = int(0.1 * len(train_dataset))\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Updated DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45214240",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0b8930d3b9e586bd5e1cef6258c3544",
     "grade": false,
     "grade_id": "cell-ca2de572d251e3c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# 4. Model Definition and Training\n",
    "In this section we will define and test the transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730459a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de078cb1746e942bd289491f50cdf3c7",
     "grade": false,
     "grade_id": "cell-4358598295ebad6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reset_all_parameters(model):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    for module in model.modules():\n",
    "        \n",
    "        # Linear layers\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "\n",
    "        # LayerNorm\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "        # MultiheadAttention (Q/K/V and output weights)\n",
    "        elif isinstance(module, nn.MultiheadAttention):\n",
    "            for name, param in module.named_parameters():\n",
    "                if param.dim() > 1:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                else:\n",
    "                    nn.init.zeros_(param)\n",
    "\n",
    "    # CLS token & positional embeddings\n",
    "    if hasattr(model, \"cls_token\"):\n",
    "        model.cls_token.data = torch.randn_like(model.cls_token)\n",
    "\n",
    "    if hasattr(model, \"pos_embed\"):\n",
    "        model.pos_embed.data = torch.randn_like(model.pos_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1406da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f69bc4766eec5debf5aa0b78e246561",
     "grade": false,
     "grade_id": "cell-92a1938ee37d048a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Follow the image below to implement the multihead attention.\n",
    "\n",
    "The formula Scaled Dot-Product Attention can be found: https://www.geeksforgeeks.org/nlp/transformer-attention-mechanism-in-nlp/\n",
    "\n",
    "Prior to calculating attention the shapes for q,k,v are (batch, heads, tokens, dim_per_head). \n",
    "\n",
    "After calculating the attention transform the attention vector back to the shape: (batch,tokens,heads*dim_per_head)\n",
    "\n",
    "![mha](mha.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdfb34",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11e3b8cdcf6457f2331a8e74cd940035",
     "grade": false,
     "grade_id": "cell-8c0f5b4e0bb358af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, feats:int, head:int=8, dropout:float=0.):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.head = head\n",
    "        self.feats = feats\n",
    "        self.sqrt_d = self.feats**0.5\n",
    "\n",
    "        self.q = nn.Linear(feats, feats)\n",
    "        self.k = nn.Linear(feats, feats)\n",
    "        self.v = nn.Linear(feats, feats)\n",
    "\n",
    "        self.o = nn.Linear(feats, feats)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, f = x.size()\n",
    "        \n",
    "        q = self.q(x).view(b, n, self.head, self.feats//self.head).transpose(1,2)\n",
    "        k = self.k(x).view(b, n, self.head, self.feats//self.head).transpose(1,2)\n",
    "        v = self.v(x).view(b, n, self.head, self.feats//self.head).transpose(1,2)\n",
    "        # q, k, v shapes:\n",
    "        # q, k, v: (batch, heads, tokens, dim_per_head)\n",
    "        ''' \n",
    "        To Do: IMPLEMENT MULTI-HEAD SELF ATTENTION HERE \n",
    "        The formula Scaled Dot-Product Attention can be found: https://www.geeksforgeeks.org/nlp/transformer-attention-mechanism-in-nlp/\n",
    "        Prior to calculating attention the shapes for q,k,v are (batch, heads, tokens, dim_per_head). \n",
    "        After calculating the attention transform the attention vector back to the shape: (batch,tokens,heads*dim_per_head)\n",
    "        You can use torch.matmul for matrix multiplication and F.softmax for softmax operation.\n",
    "        The answer should be assigned to the variable 'attn' below.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        o = self.dropout(self.o(attn))\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8cd82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29c3f45ab3900bfb5e646f847b5b5ba6",
     "grade": false,
     "grade_id": "cell-3ecb251d2c6d2fb5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "In the following section we will define and implement the trasnformer encoder given in the image below.\n",
    "\n",
    "![encoder](encoder.png)\n",
    "\n",
    "Follw the instructions in To Do sections to initialize the layers and define the forward function of the vision transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab85e6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03db150a0af4183a1f18a19265fecf36",
     "grade": false,
     "grade_id": "cell-149fc9eeb325152f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vision Transformer definition\n",
    "class MiniViT(nn.Module):\n",
    "    def __init__(self, patch_size=7, embed_dim=64, num_heads=4, num_classes=10, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # image 28x28 -> (28/7)^2 = 16 patches\n",
    "        self.num_patches = (28 // patch_size) ** 2\n",
    "\n",
    "        self.patch_embed = nn.Linear(patch_size * patch_size, embed_dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, self.num_patches + 1, embed_dim))\n",
    "\n",
    "        self.mha=None   \n",
    "        self.ln1=None\n",
    "        self.ln2=None\n",
    "        self.ff=None\n",
    "        self.fc=None\n",
    "        '''\n",
    "        To Do: Initialize the following layers:\n",
    "        1. MultiHeadSelfAttention layer (self.mha) with MultiHeadSelfAttention class and embed_dim and num_heads\n",
    "        2. LayerNorm layer (self.ln1) with nn.LayerNorm and embed_dim\n",
    "        3. LayerNorm layer (self.ln2) with nn.LayerNorm and embed_dim\n",
    "        4. Feed-Forward network (self.ff) as a sequential model with:\n",
    "            - Linear layer from embed_dim to embed_dim*2\n",
    "            - GELU activation\n",
    "            - Linear layer from embed_dim*2 to embed_dim\n",
    "        5. Final classification layer (self.fc) with nn.Linear from embed_dim to num_classes\n",
    "        \n",
    "        '''\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        \n",
    "\n",
    "        # divide into patches\n",
    "        patches = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
    "        patches = patches.contiguous().view(B, 1, -1, self.patch_size*self.patch_size).squeeze(1)\n",
    "\n",
    "        # linear embedding\n",
    "        x = self.patch_embed(patches)\n",
    "\n",
    "        # prepend cls token\n",
    "        cls = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls, x], dim=1) # (B, num_patches+1, embed_dim)\n",
    "        \n",
    "        # add positional embedding\n",
    "        x = x + self.pos_embed\n",
    "        '''\n",
    "         To Do: Implement the Transformer encoder block here:\n",
    "         1. Apply multi-head self-attention (self.mha) to x\n",
    "         2. Apply layer normalization (self.ln) then residual connection from before attention\n",
    "         3. Apply feed-forward network (self.ff)\n",
    "         4. Apply another  layer normalization (self.ln) then residual connection from before feed-forward\n",
    "         \n",
    "         Finally, classify using the cls token with the final linear layer (self.fc)\n",
    "         The result should be assigned to the variable 'out' below.\n",
    "        ''' \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3ac9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dc85648268c21740f2ed6c71d71c4ee",
     "grade": false,
     "grade_id": "cell-0cf93e90b23b9d32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 5.1 Training Setup\n",
    "\n",
    "The model will train and test for few epochs\n",
    "\n",
    "We will use:\n",
    "- **Loss:** CrossEntropyLoss  \n",
    "- **Optimizer:** Adam (learning rate = 1e-3)  \n",
    "- **Metric:** Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e6c73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "633e277d2e4189b078e84eec4b82fb32",
     "grade": false,
     "grade_id": "cell-02acd6beb7bad83c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model = MiniViT().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b158b39",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce7c9860e822a425c2e6412640ff0f22",
     "grade": false,
     "grade_id": "cell-8c097795f465a534",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reset_all_parameters(model)\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb25f33",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "467b87c43369a34c66076edd527b5b6a",
     "grade": false,
     "grade_id": "cell-433f8a1294e6d49c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(predicted.dtype, labels.dtype)\n",
    "f1_score(predicted.cpu().numpy(), labels.cpu().numpy(), average='macro')\n",
    "print('F1 Score:', f1_score(predicted.cpu().numpy(), labels.cpu().numpy(), average='macro'))\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c72d5f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e706e5fd33a7ecd9085bc07bbd885763",
     "grade": true,
     "grade_id": "cell-6c1e98de5e49da5e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden test cases that will be evaluated after submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bbccda",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c55d652a3f442b2b0821351e01e0e383",
     "grade": true,
     "grade_id": "cell-257ebc61edfeb6ac",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden test cases that will be evaluated after submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "nbgrader": {
   "assignment": "Exercise1",
   "grade": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
