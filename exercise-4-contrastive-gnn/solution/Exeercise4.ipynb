{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "wwbL-N5OmOHo",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bd1f9972c4bf3dc514535ced1411e1b6",
          "grade": false,
          "grade_id": "cell-aaeb6c75aaa46acb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "# **Exercise 4: Graph convolution networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8gzsP50bF6Gb",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3572cff8f069ff6d79c445293a3fcb3a",
          "grade": false,
          "grade_id": "cell-20aaf75e965c049d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "In this exercise, we will construct our own graph neural network by using PyTorch Geometric (PyG) and apply the model on one of Open Graph Benchmark (OGB) datasets. Those two datasets are used to benchmark the model performance on node property prediction, predicting properties of single nodes graph-related tasks.\n",
        "\n",
        "  We will build our own graph neural networks by using PyTorch Geometric. And then apply and evaluate the models on node property prediction and grpah property prediction tasks.\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell.\n",
        "You would need to use **GPU** for the exercise so please check the runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Sf7vUmdNKCjA",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9bc1fff4fa249fa4f939e474a033f6dc",
          "grade": false,
          "grade_id": "cell-20bdd7717809bbbd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "PyTorch Geometric generally has two classes for storing or transforming the graphs into tensor format. One is the `torch_geometric.datasets`, which contains a variety of common graph datasets. Another one is `torch_geometric.data` that provides the data handling of graphs in PyTorch tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AXa7yIG4E0Fp",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "08b00f47c0c1600c7dae928829713db4",
          "grade": false,
          "grade_id": "cell-1679d6c2cba2c985",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "### Open Graph Benchmark (OGB)\n",
        "\n",
        "The Open Graph Benchmark (OGB) is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. Its datasets are automatically downloaded, processed, and split using the OGB Data Loader. The model performance can also be evaluated by using the OGB Evaluator in a unified manner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "LIzzXIi_SxOT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0ef3108e78522f42c3bb224d27488965",
          "grade": true,
          "grade_id": "cell-f5c22980741298fd",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Do not delete this cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8cedd460d8461aa401a6d7ce20f64dfc",
          "grade": false,
          "grade_id": "cell-1ea7b182c5479c5d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "WyK4jUjQwCQm"
      },
      "source": [
        "## 1. Import Necessary Libraries\n",
        "\n",
        "In this section, we import the essential Python libraries required for building, training, and evaluating our convolutional residual networks.\n",
        "\n",
        "We will use:\n",
        "- **PyTorch** for model definition, training, and evaluation.  \n",
        "- **Torch_geometric** for loading and transforming the dataset.  \n",
        "- **NumPy** for  numerical operations.  \n",
        "- **tqdm** for tracking training progress.\n",
        "\n",
        "Make sure all required packages are installed before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yewVXlUc3lHF",
        "outputId": "e38bbf5a-299e-4b8f-c3f4-425c8322387b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.12/dist-packages (1.3.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (2.5.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.12/dist-packages (from outdated>=0.2.0->ogb) (75.2.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.12/dist-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from outdated>=0.2.0->ogb) (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->ogb) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.0->ogb) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.0->ogb) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->ogb) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.6.0->ogb) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.6.0->ogb) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->outdated>=0.2.0->ogb) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->outdated>=0.2.0->ogb) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "Gpc6bTm3GF02",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7db81dcd0b6800fb437bfc2596f168f2",
          "grade": false,
          "grade_id": "cell-8964ec1c4c0706f0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "68d93126-3da7-4664-9af0-368b20a6d131",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b67f51821b0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import copy\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import TUDataset\n",
        "import torch_geometric.transforms as T\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "from torch_geometric.nn import GCNConv\n",
        "# Optional: For reproducibility\n",
        "import random\n",
        "\n",
        "# Allowlist the required PyG classes\n",
        "torch.serialization.add_safe_globals([\n",
        "    torch_geometric.data.storage.GlobalStorage,\n",
        "    torch_geometric.data.data.DataEdgeAttr,   # from previous error\n",
        "    torch_geometric.data.data.DataTensorAttr  # from current error\n",
        "])\n",
        "\n",
        "# Set seeds\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9DP_yEQZ0NVW",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8813f51cd969d4e79d88b1af2ccbae46",
          "grade": false,
          "grade_id": "cell-1311cf81cf0cab4d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "# GNN: Node Property Prediction\n",
        "\n",
        "In this section we will build our first graph neural network by using PyTorch Geometric and apply it on node property prediction (node classification).\n",
        "\n",
        "We will build the graph neural network by using GCN operator ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)).\n",
        "\n",
        "You should use the PyG built-in `GCNConv` layer directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0IK9z0wQIwzQ",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1fd556aa58d4e640c978da7061a782ba",
          "grade": false,
          "grade_id": "cell-834079ff608f0e0a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "## 2. Download and Load the MNIST Dataset\n",
        "In this section we will load ogbn-arxiv. This dataset contains the graph network for published research papers and the papers are sorted into different categories based on the provided embeddings and the citation network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0ibJ0ieoIwQM",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8632bbd362dc4956d5ba894ca3f69785",
          "grade": false,
          "grade_id": "cell-9e42e6ef535ec865",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f768b366-f07e-490c-82de-cc8fd80a577f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.08 GB: 100%|██████████| 81/81 [00:01<00:00, 71.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into PyG objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 552.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Done!\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/sparse.py:276: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  adj = torch.sparse_csr_tensor(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "dataset_name = 'ogbn-arxiv'\n",
        "# dataset = PygNodePropPredDataset(name=dataset_name, transform=T.ToSparseTensor())  # old version of PyG\n",
        "dataset=PygNodePropPredDataset(name=dataset_name, transform=T.Compose([T.ToUndirected(), T.ToSparseTensor()]))\n",
        "\n",
        "data = dataset[0]\n",
        "\n",
        "# Make the adjacency matrix to symmetric\n",
        "#data.adj_t = data.adj_t.to_symmetric()  # old version of PyG\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# If you use GPU, the device should be cuda\n",
        "print('Device: {}'.format(device))\n",
        "\n",
        "\n",
        "data.to(device)\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx = split_idx['train'].to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "3j3odjkjWWi4",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3d8c0da8c6ba2d85b406b721da5cc169",
          "grade": false,
          "grade_id": "cell-9f38a4e7b0b2d0b2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2470c118-6952-4074-c2d4-d28d55b7e465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ogbn-arxiv dataset has 1 graph\n",
            "Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343])\n"
          ]
        }
      ],
      "source": [
        "print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "GhleuzjqXXci",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5915dad588718322526e3637bb631988",
          "grade": false,
          "grade_id": "cell-19e86f39f0ca953f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "| Attribute   | Shape            | Meaning                                                                |\n",
        "| ----------- | ---------------- | ---------------------------------------------------------------------- |\n",
        "| `num_nodes` | 169,343          | Total number of nodes (papers)                                         |\n",
        "| `x`         | [169343, 128]    | Node features: 128-dimensional embeddings for each paper               |\n",
        "| `node_year` | [169343, 1]      | Year of publication for each paper (used as a label)                   |\n",
        "| `y`         | [169343, 1]      | Node labels        |\n",
        "| `adj_t`     | [169343, 169343] | Sparse adjacency matrix of the citation network (sparse tensor format) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "OgUA815bNJ8w",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "97fff66a1c168fd8a178027f2295492c",
          "grade": false,
          "grade_id": "cell-42c61326abf0c097",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "# 3. Model Definition and Training for GCN Model\n",
        "\n",
        "In the following section we will now we will design implement our GCN model!\n",
        "The following model contains convolution layers, batch normalization layers and softmax layer.\n",
        "\n",
        "Please follow the figure below to implement your `forward` function.\n",
        "\n",
        "\n",
        "![model architecture](model_arch.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "id": "IgspXTYpNJLA",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "021317c123b41883f3d774f721523876",
          "grade": false,
          "grade_id": "cell-9a32725d2cbec737",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
        "                 dropout, return_embeds=False):\n",
        "        # TODO: Implement this function that initializes self.convs,\n",
        "        # self.bns, and self.softmax.\n",
        "\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        TODO: Implement this function that initializes self.convs,\n",
        "        self.bns, and self.softmax.\n",
        "        Note:\n",
        "        1. You should use torch.nn.ModuleList for self.convs and self.bns\n",
        "        2. self.convs has num_layers GCNConv layers. use input_dim, hidden_dim, and output_dim for in_channels and out_channels.\n",
        "        First layer takes input_dim, hidden_dim and last layer outputs hidden_dim, output_dim\n",
        "        3. self.bns has num_layers - 1 BatchNorm1d layers\n",
        "        4. You should use torch.nn.LogSoftmax for self.softmax\n",
        "        5. The parameters you can set for GCNConv include 'in_channels' and\n",
        "        'out_channels'.\n",
        "        6. The only parameter you need to set for BatchNorm1d is 'num_features'\n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        # A list of GCNConv layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        # first layer\n",
        "        self.convs.append(GCNConv(input_dim, hidden_dim))\n",
        "        # middle layers (if any)\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
        "        # last layer\n",
        "        self.convs.append(GCNConv(hidden_dim, output_dim))\n",
        "\n",
        "        # A list of 1D batch normalization layers\n",
        "        self.bns = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "        # The log softmax layer\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
        "\n",
        "        # Probability of an element to be zeroed\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Skip classification layer and return node embeddings\n",
        "        self.return_embeds = return_embeds\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "\n",
        "\n",
        "        out = x\n",
        "        \"\"\"\n",
        "        TODO: Implement this function that takes the feature tensor x,\n",
        "        edge_index tensor adj_t and returns the output tensor as\n",
        "        shown in the figure.\n",
        "        Note:\n",
        "        1. Construct the network as showing in the figure\n",
        "        2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n",
        "        3. Don't forget to set F.dropout training to self.training\n",
        "        4. If return_embeds is True, then skip the last softmax layer\n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        for i in range(len(self.convs) - 1):\n",
        "            out = self.convs[i](out, adj_t)\n",
        "            out = self.bns[i](out)\n",
        "            out = F.relu(out)\n",
        "            out = F.dropout(out, p=self.dropout, training=self.training)\n",
        "        out = self.convs[-1](out, adj_t)\n",
        "        if self.return_embeds:\n",
        "            return out\n",
        "        out = self.softmax(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "id": "FF1hnHUhO81e",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "17c1e9cfc27080aae67d1b680b1fbc80",
          "grade": false,
          "grade_id": "cell-7c2c4f882ca13db1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train(model, data, train_idx, optimizer, loss_fn):\n",
        "\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "    \"\"\"\n",
        "    TODO: Implement this function that trains the model by\n",
        "    using the given optimizer and loss_fn.\n",
        "    Note:\n",
        "    1. Zero grad the optimizer\n",
        "    2. Feed the data into the model\n",
        "    3. Slicing the model output and label by train_idx\n",
        "    4. Feed the sliced output and label to loss_fn\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.adj_t)\n",
        "    out_train = out[train_idx]\n",
        "    y_train = data.y[train_idx].squeeze(1)\n",
        "    loss = loss_fn(out_train, y_train)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "deletable": false,
        "id": "aJdlrJQhPBsK",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "443c3a20485e551c508c0c26dc31c622",
          "grade": false,
          "grade_id": "cell-c5f6324dd944d49e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Test function here\n",
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, evaluator):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # The output of model on all data\n",
        "    out = None\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    TODO: Implement this function that tests the model by\n",
        "    using the given split_idx and evaluator.\n",
        "    Note:\n",
        "    1. No index slicing here\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    out = model(data.x, data.adj_t)\n",
        "\n",
        "\n",
        "\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, valid_acc, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dT8RyM2cPGxM",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6dbbdb3d5329de860c33b9fd456a8f99",
          "grade": false,
          "grade_id": "cell-1aede8ef38c93ec6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Please do not change the args\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 3,\n",
        "    'hidden_dim': 256,\n",
        "    'dropout': 0.5,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 100,\n",
        "}\n",
        "model = GCN(data.num_features, args['hidden_dim'],\n",
        "            dataset.num_classes, args['num_layers'],\n",
        "            args['dropout']).to(device)\n",
        "evaluator = Evaluator(name='ogbn-arxiv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "qd5O5cnPPdVF",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "94e6f44747e4e9146d4644af9ea950d3",
          "grade": false,
          "grade_id": "cell-77d1ebf96bab2d32",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "d48cfe0f-ac16-4bc0-8153-d1c6e5be74e9",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 1.3733, Train: 41.49%, Valid: 35.19% Test: 37.99%\n",
            "Epoch: 20, Loss: 1.1861, Train: 53.97%, Valid: 52.95% Test: 52.70%\n",
            "Epoch: 30, Loss: 1.0919, Train: 64.93%, Valid: 64.83% Test: 65.32%\n",
            "Epoch: 40, Loss: 1.0443, Train: 69.47%, Valid: 68.41% Test: 67.57%\n",
            "Epoch: 50, Loss: 1.0108, Train: 70.84%, Valid: 70.35% Test: 69.95%\n",
            "Epoch: 60, Loss: 0.9848, Train: 71.88%, Valid: 70.90% Test: 70.47%\n",
            "Epoch: 70, Loss: 0.9611, Train: 72.64%, Valid: 71.35% Test: 70.58%\n",
            "Epoch: 80, Loss: 0.9423, Train: 73.11%, Valid: 71.51% Test: 70.57%\n",
            "Epoch: 90, Loss: 0.9260, Train: 73.43%, Valid: 71.59% Test: 70.75%\n",
            "Epoch: 100, Loss: 0.9101, Train: 73.82%, Valid: 71.45% Test: 70.32%\n"
          ]
        }
      ],
      "source": [
        "# reset the parameters to initial random value\n",
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = F.nll_loss\n",
        "\n",
        "best_model = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "  loss = train(model, data, train_idx, optimizer, loss_fn)\n",
        "  result = test(model, data, split_idx, evaluator)\n",
        "  train_acc, valid_acc, test_acc = result\n",
        "  if valid_acc > best_valid_acc:\n",
        "      best_valid_acc = valid_acc\n",
        "      best_model = copy.deepcopy(model)\n",
        "  if epoch%10==0:\n",
        "    print(f'Epoch: {epoch:02d}, 'f'Loss: {loss:.4f}, 'f'Train: {100 * train_acc:.2f}%, 'f'Valid: {100 * valid_acc:.2f}% 'f'Test: {100 * test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EqcextqOL2FX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "51da82b0b3727260cb56d12de4bdf42c",
          "grade": false,
          "grade_id": "cell-e140bb0781ddc3a8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8238e4bc-4ea2-4dde-cf99-99f09202c497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: Train: 73.82%, Valid: 71.45% Test: 70.32%\n"
          ]
        }
      ],
      "source": [
        "best_result = test(model, data, split_idx, evaluator)\n",
        "train_acc, valid_acc, test_acc = best_result\n",
        "print(f'Best model: '\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * valid_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "be12720b5473113c92df4d4eab1e19c9",
          "grade": true,
          "grade_id": "cell-3a2687dec5c94f5b",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": [],
        "id": "0gx7b1wOwCQr"
      },
      "outputs": [],
      "source": [
        "# This cell contains hidden test cases that will be evaluated after submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Rw1FeIz3P2m7",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a06cfbfa63d28faaf00516d60ea5c784",
          "grade": true,
          "grade_id": "cell-e68b4090b5c82515",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This cell contains hidden test cases that will be evaluated after submission"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}