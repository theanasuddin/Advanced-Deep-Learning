{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4c0d92",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7989c265cfad1f1f9fc4983cf2657f1",
     "grade": true,
     "grade_id": "cell-8e5b7b6d7f4d94b2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Image regeneration using VAE \n",
    "\n",
    "In this exercise we will create VAE encoder decoder network to compress the image and them regenerate the image from the compressed state.\n",
    "We will use the **Mint dataset** — a small image dataset.\n",
    "\n",
    "### **Stages**\n",
    "\n",
    "1. **Import Necessary Libraries** – Load required Python and deep learning packages.  \n",
    "2. **Download and Load the MNIST Dataset** – Explore its structure and format.  \n",
    "3. **Preprocess and Prepare DataLoaders** – Normalize, resize, and split the dataset into training, validation, and test sets. \n",
    "5. **Define and Train Models** – Implement the VAE network. \n",
    "Complete the code blocks marked with:\n",
    "\n",
    "```python\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a54a8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1c46584d86ed59be71c6f7c966e9df2",
     "grade": false,
     "grade_id": "cell-e5c3fea256e940c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1. Import Necessary Libraries\n",
    "\n",
    "In this section, we import the essential Python libraries required for building, training, and evaluating our convolutional residual networks.\n",
    "\n",
    "We will use:\n",
    "- **PyTorch** for model definition, training, and evaluation.  \n",
    "- **Torchvision** for loading and transforming the MNIST dataset. \n",
    "- **Seaborn and matplotlib** for image visualization and dataset exploring. \n",
    "- **NumPy** for numerical operations.  \n",
    "- **Random** for setting the random seed. \n",
    "- **tqdm** for tracking training progress.\n",
    "\n",
    "Make sure all required packages are installed before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a5b1d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cb8573f700d909031b35d42949cbd97",
     "grade": false,
     "grade_id": "cell-fc85de19aad910dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "\n",
    "from torchvision import datasets \n",
    "import torchvision.transforms as tfs\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.manual_seed_all(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66057322",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d40f795bcb759b14d78d9e196b76cea",
     "grade": false,
     "grade_id": "cell-8897261b66237832",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 2. Download, Load and preprocess the MNIST Dataset \n",
    "\n",
    "In this section, we will download the **MNIST** dataset, which contains **60,000 training** and **10,000 test** grayscale images of handwritten digits (0–9), each of size **28×28 pixels**.\n",
    "\n",
    "We will:\n",
    "- Use `torchvision.datasets.MNIST` to download and load the data.  \n",
    "- Apply image transformations such as **tensor conversion** and **normalization** to ensure consistent model training.  \n",
    "- Create **DataLoaders** for both training and testing sets, enabling efficient mini-batch processing.\n",
    "\n",
    "### Normalization Details\n",
    "The images are normalized using the mean and standard deviation of the MNIST dataset:\n",
    "- Mean = 0.1307  \n",
    "- Std  = 0.3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e1b23",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "120dd5413942c3c51a7b6a0e862ada7f",
     "grade": false,
     "grade_id": "cell-c156ffd766d1e51e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = tfs.Compose([\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define DataLoaders for batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9caa9af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cce1a825dd8ec51fcdc06cad86f8dbff",
     "grade": false,
     "grade_id": "cell-60f80096b1e2e61a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bdabd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2985d72c929b61cbc9a19fdb9ef466f",
     "grade": false,
     "grade_id": "cell-de6425de9745c4cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(train_loader.dataset.data) , len(train_loader.dataset.targets) , len(test_loader.dataset.data) , len(test_loader.dataset.targets))\n",
    "classes = train_dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0fd49",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1c6805cc10cc4882c34885bce91f061",
     "grade": false,
     "grade_id": "cell-0baca076c731abd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "rows,cols = 4,4\n",
    "\n",
    "for i in range(1,cols*rows+1):\n",
    "    random_idx = torch.randint(0,len(train_loader.dataset),size=[1]).item()\n",
    "    img,label = train_loader.dataset[random_idx]\n",
    "    fig.add_subplot(rows,cols,i)\n",
    "    plt.imshow(img.squeeze(),cmap='gray')\n",
    "    plt.title(classes[label])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c883cd1a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "999fb8aa5d7a07fcf484e5ef513fd29f",
     "grade": false,
     "grade_id": "cell-6262d2af185dee7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# 4. Model Definition and Training\n",
    "In this section we will define and test the Variational Autoencoder block. Implement the model according to the given instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db1a378",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "711d1e48f60b1723e87775dd8ccdc25d",
     "grade": false,
     "grade_id": "cell-f9a11a202ea501a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,z_dim=2):\n",
    "        super().__init__()\n",
    "        self.encoder = None\n",
    "        self.fc_mu = None\n",
    "        self.fc_var = None\n",
    "        ''' \n",
    "        TODO: Define the encoder part of the VAE according to the architecture described.\n",
    "        use nn.Sequential to stack the layers.\n",
    "        The encoder should consist of:\n",
    "        - Conv2d layer with 32 filters, kernel size 3, padding 1, followed by BatchNorm2d and ReLU activation\n",
    "        - Conv2d layer with 64 filters, kernel size 3, padding 1, stride 2, followed by BatchNorm2d and ReLU activation\n",
    "        - Conv2d layer with 64 filters, kernel size 3, padding 1, stride 2, followed by BatchNorm2d and ReLU activation\n",
    "        - finally followed by nn.Flatten() layer to flatten the output.\n",
    "        After the encoder, define two fully connected layers (self.fc_mu and self.fc_var) to map the output of the encoder to the mean and log variance of the latent space.\n",
    "        The input to these layers should be of size 64*7*7 (the output size of the encoder) and the output size should be z_dim.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        self.decoder = None\n",
    "        '''\n",
    "        Todo: Define the decoder part of the VAE according to the architecture described.\n",
    "        use nn.Sequential to stack the layers.\n",
    "        The decoder should consist of:\n",
    "        - A fully connected layer that maps from z_dim to 64*7*7\n",
    "        - Unflatten layer to reshape the output to (64,7,7)\n",
    "        - ConvTranspose2d layer with 64 filters, kernel size 3, padding 1, output padding 1, stride 2, followed by BatchNorm2d and ReLU activation\n",
    "        - ConvTranspose2d layer with 32 filters, kernel size 3, padding 1, output padding 1, stride 2, followed by BatchNorm2d and ReLU activation\n",
    "        - A final ConvTranspose2d layer with 1 filter, kernel size 3, padding 1, followed by Sigmoid activation to output the reconstructed image.\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        self.latent = torch.empty(z_dim)\n",
    "        self.mu = None\n",
    "        self.log_var = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        '''\n",
    "        TODO: Implement the forward pass of the VAE.\n",
    "        - Pass the input x through the encoder to get the encoded representation.\n",
    "        - Compute the mean (self.mu) and log variance (self.sigma) of the latent space.\n",
    "        - Sample from the latent space using the reparameterization trick: z = mu + sigma * eps, where eps is sampled from a standard normal distribution.\n",
    "        - Pass the sampled latent vector z through the decoder to get the reconstructed output.\n",
    "        - Store the sampled latent vector in self.latent for later use.\n",
    "        - Return the reconstructed output.\n",
    "\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6b895",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f5561d47f7bca165c966a748e276d9b",
     "grade": false,
     "grade_id": "cell-3ea1b71ac63c4954",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ae = AutoEncoder().to(DEVICE)\n",
    "torchsummary.summary(ae, input_size=(1, 28, 28), device=str(DEVICE))\n",
    "del ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4871b46",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9467ab3da83c3c29538d86dc4b9f6c70",
     "grade": false,
     "grade_id": "cell-c4bded42ca7881d0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KLDivergenceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,mu: torch.Tensor, logsigma: torch.Tensor):\n",
    "        '''\n",
    "        TODO: Implement the KL Divergence loss between the learned latent distribution and the standard normal distribution.\n",
    "        The formula for KL Divergence in this case is:\n",
    "        KL(N(mu, sigma) || N(0, 1)) = -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        the logsigma parameter represents log(sigma^2)\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return Kl\n",
    "\n",
    "class VAELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.kl_divergence = KLDivergenceLoss()\n",
    "        self.log_likelihood = nn.MSELoss()\n",
    "    \n",
    "    def forward(self,mu,logsigma,outputs,labels):\n",
    "        return self.kl_divergence(mu,logsigma)+self.log_likelihood(outputs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8f3b4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d59cecc173b89ad1b56a7136ec7fe0da",
     "grade": false,
     "grade_id": "cell-e276be330215c6b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoEncoder(z_dim=2).to(DEVICE)\n",
    "\n",
    "EPOCHS = 4\n",
    "criterion = VAELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    \n",
    "    trainloss = 0\n",
    "    acc_epoch = 0\n",
    "    for batch,(X,y) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        X=X.to(DEVICE)\n",
    "        y_pred = model(X).to(DEVICE)\n",
    "        mu,logsigma = model.mu,model.sigma\n",
    "        \n",
    "        \n",
    "        loss = criterion(mu,logsigma,y_pred,X.float())\n",
    "        loss_ = loss.detach().cpu().item()\n",
    "        trainloss += loss_\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "   \n",
    "    trainloss /=len(train_loader)\n",
    "    train_losses.append(trainloss)\n",
    "    \n",
    "    testloss = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X,y in test_loader:\n",
    "            X = X.to(DEVICE)\n",
    "            test_pred=model(X).to(DEVICE)\n",
    "            mu_test,logsigma_test = model.mu,model.sigma\n",
    "            loss = criterion(mu,logsigma,test_pred,X.float())\n",
    "            loss_test_ = loss.detach().cpu().item()\n",
    "            testloss+=loss_test_\n",
    "        testloss /= len(test_loader)  \n",
    "    \n",
    "    test_losses.append(testloss)\n",
    "    \n",
    "    print(f\"\\nTrain loss: {trainloss:.5f} | Test loss: {testloss:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724211f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5c8fc5b9a18e43b76064ee347e039de",
     "grade": false,
     "grade_id": "cell-1d4700b0b70865ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('VAE losses')\n",
    "sns.lineplot(x=range(len(train_losses)), y=train_losses)\n",
    "sns.lineplot(x=range(len(test_losses)), y=test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf9e75",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5965e7b798136042cb78c731fb9ec8c9",
     "grade": true,
     "grade_id": "cell-ada6860fadba86b7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden test cases that will be evaluated after submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11906cbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4c04d3d11be371cd3bec3d736c3e019",
     "grade": true,
     "grade_id": "cell-675e45bd328cc5f3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden test cases that will be evaluated after submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
